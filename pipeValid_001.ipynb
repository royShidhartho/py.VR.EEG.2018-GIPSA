{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sid/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from virtualreality.dataset import VirtualReality\n",
    "from virtualreality.utilities import get_block_repetition\n",
    "\n",
    "import numpy as np\n",
    "import mne\n",
    "import moabb\n",
    "import pandas as pd\n",
    "\n",
    "from moabb.paradigms import P300\n",
    "from pyriemann.estimation import ERPCovariances\n",
    "from pyriemann.classification import MDM\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "=============================\n",
    "Classification of the trials\n",
    "=============================\n",
    "\n",
    "This example shows how to extract the epochs from the dataset of a given\n",
    "subject and then classify them using Riemannian Geometry framework for BCI. \n",
    "We compare the scores in the VR and PC conditions.\n",
    "\n",
    "Authors: Pedro Rodrigues <pedro.rodrigues01@gmail.com>\n",
    "\n",
    "License: BSD (3-clause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dataset class name 'VirtualReality' must be an abbreviation of its code 'Virtual-Reality-Dataset'. See moabb.datasets.base.is_abbrev for more information.\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default location ~/mne_data for VIRTUALREALITY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://zenodo.org/record/2605205/files/subject_01_VR.mat' to file '/Users/sid/mne_data/MNE-virtualreality-data/record/2605205/files/subject_01_VR.mat'.\n",
      "SHA256 hash of downloaded file: 6d1db2b938e935af09ff284dc70c76c53352989f92115a8f4db79136eb031153\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "  0%|          | 0/5 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_info() got an unexpected keyword argument 'montage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \tdataset\u001b[38;5;241m.\u001b[39mPC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# get the epochs and labels\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m X, labels, meta \u001b[38;5;241m=\u001b[39m \u001b[43mparadigm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m labels \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(labels)\n\u001b[1;32m     32\u001b[0m kf \u001b[38;5;241m=\u001b[39m KFold(n_splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/paradigms/base.py:279\u001b[0m, in \u001b[0;36mBaseProcessing.get_data\u001b[0;34m(self, dataset, subjects, return_epochs, return_raws, cache_config, postprocess_pipeline)\u001b[0m\n\u001b[1;32m    274\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    275\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    276\u001b[0m )\n\u001b[1;32m    277\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[0;32m--> 279\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess_pipelines\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    288\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    289\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/paradigms/base.py:280\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m process_pipelines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_process_pipelines(\n\u001b[1;32m    275\u001b[0m     dataset, return_epochs, return_raws, postprocess_pipeline\n\u001b[1;32m    276\u001b[0m )\n\u001b[1;32m    277\u001b[0m labels_pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_labels_pipeline(dataset, return_epochs, return_raws)\n\u001b[1;32m    279\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m process_pipeline \u001b[38;5;129;01min\u001b[39;00m process_pipelines\n\u001b[1;32m    286\u001b[0m ]\n\u001b[1;32m    288\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    289\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/datasets/base.py:343\u001b[0m, in \u001b[0;36mBaseDataset.get_data\u001b[0;34m(self, subjects, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_list:\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid subject \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subject))\n\u001b[0;32m--> 343\u001b[0m     data[subject] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single_subject_data_using_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m check_subject_names(data)\n\u001b[1;32m    349\u001b[0m check_session_names(data)\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/datasets/base.py:437\u001b[0m, in \u001b[0;36mBaseDataset._get_single_subject_data_using_cache\u001b[0;34m(self, subject, cache_config, process_pipeline)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Load and eventually overwrite:\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cached_steps) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# last option: we don't use cache\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     sessions_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_single_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sessions_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# should not happen\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/virtualreality/dataset.py:83\u001b[0m, in \u001b[0;36mVirtualReality._get_single_subject_data\u001b[0;34m(self, subject)\u001b[0m\n\u001b[1;32m     80\u001b[0m chtypes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     81\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([S, stim[:, \u001b[38;5;28;01mNone\u001b[39;00m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 83\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mch_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmontage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstandard_1020\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43museMontagePosition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m idx_stim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(stim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m idx_blockStart \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(data[:,\u001b[38;5;241m20\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: create_info() got an unexpected keyword argument 'montage'"
     ]
    }
   ],
   "source": [
    "\n",
    "# create dataset\n",
    "dataset = VirtualReality()\n",
    "\n",
    "# get the paradigm\n",
    "paradigm = P300()\n",
    "\n",
    "# loop to get scores for each subject\n",
    "nsubjects = 5\n",
    "\n",
    "df = {}\n",
    "for tmax in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "\n",
    "\tparadigm.tmax = tmax\n",
    "\n",
    "\tscores = []\n",
    "\tfor subject in tqdm(dataset.subject_list[:nsubjects]):\n",
    "\t\tscores_subject = [subject]\n",
    "\t\tfor condition in ['VR', 'PC']:\n",
    "\n",
    "\t\t\t# define the dataset instance\n",
    "\t\t\tif condition == 'VR':\n",
    "\t\t\t\tdataset.VR = True\n",
    "\t\t\t\tdataset.PC = False\n",
    "\t\t\telif condition == 'PC':\n",
    "\t\t\t\tdataset.VR = False\n",
    "\t\t\t\tdataset.PC = True\n",
    "\n",
    "\t\t\t# get the epochs and labels\n",
    "\t\t\tX, labels, meta = paradigm.get_data(dataset, subjects=[subject])\n",
    "\t\t\tlabels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "\t\t\tkf = KFold(n_splits = 6)\n",
    "\t\t\trepetitions = [1, 2]\t\t\t\t\n",
    "\t\t\tauc = []\n",
    "\n",
    "\t\t\tblocks = np.arange(1, 12+1)\n",
    "\t\t\tfor train_idx, test_idx in kf.split(np.arange(12)):\n",
    "\n",
    "\t\t\t\t# split in training and testing blocks\n",
    "\t\t\t\tX_training, labels_training, _ = get_block_repetition(X, labels, meta, blocks[train_idx], repetitions)\n",
    "\t\t\t\tX_test, labels_test, _ = get_block_repetition(X, labels, meta, blocks[test_idx], repetitions)\n",
    "\n",
    "\t\t\t\t# estimate the extended ERP covariance matrices with Xdawn\n",
    "\t\t\t\tdict_labels = {'Target':1, 'NonTarget':0}\n",
    "\t\t\t\terpc = ERPCovariances(classes=[dict_labels['Target']], estimator='lwf')\n",
    "\t\t\t\terpc.fit(X_training, labels_training)\n",
    "\t\t\t\tcovs_training = erpc.transform(X_training)\n",
    "\t\t\t\tcovs_test = erpc.transform(X_test)\n",
    "\n",
    "\t\t\t\t# get the AUC for the classification\n",
    "\t\t\t\tclf = MDM()\n",
    "\t\t\t\tclf.fit(covs_training, labels_training)\n",
    "\t\t\t\tlabels_pred = clf.predict(covs_test)\n",
    "\t\t\t\tauc.append(roc_auc_score(labels_test, labels_pred))\n",
    "\n",
    "\t\t\t# stock scores\n",
    "\t\t\tscores_subject.append(np.mean(auc))\n",
    "\n",
    "\t\tscores.append(scores_subject)\n",
    "\n",
    "\t# print results\n",
    "\tdf[tmax] = pd.DataFrame(scores, columns=['subject', 'VR', 'PC'])\n",
    "\n",
    "filename = './results.pkl'\n",
    "joblib.dump(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "code 'Virtual Reality dataset' must be in Camel-KebabCase; i.e. use CamelCase, and add dashes where absolutely necessary. See moabb.datasets.base.is_camel_kebab_case for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# create datasets\u001b[39;00m\n\u001b[1;32m      6\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 7\u001b[0m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mVirtualReality\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mVR \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mPC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/virtualreality/dataset.py:51\u001b[0m, in \u001b[0;36mVirtualReality.__init__\u001b[0;34m(self, VR, PC, useMontagePosition)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, VR\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, PC\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, useMontagePosition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43msessions_per_subject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNonTarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVirtual Reality dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparadigm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp300\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdoi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mVR \u001b[38;5;241m=\u001b[39m VR\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPC \u001b[38;5;241m=\u001b[39m PC\n",
      "File \u001b[0;32m~/Documents/GitHub/XR_EEG_pipeline_validation/py.VR.EEG.2018-GIPSA/env_311/lib/python3.11/site-packages/moabb/datasets/base.py:240\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, subjects, sessions_per_subject, events, code, interval, paradigm, doi, unit_factor)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjects must be a iterable, like a list\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_camel_kebab_case(code):\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m must be in Camel-KebabCase; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. use CamelCase, and add dashes where absolutely necessary. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee moabb.datasets.base.is_camel_kebab_case for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_abbrev(class_name, code):\n",
      "\u001b[0;31mValueError\u001b[0m: code 'Virtual Reality dataset' must be in Camel-KebabCase; i.e. use CamelCase, and add dashes where absolutely necessary. See moabb.datasets.base.is_camel_kebab_case for more information."
     ]
    }
   ],
   "source": [
    "# get the paradigm\n",
    "paradigm = P300()\n",
    "paradigm.tmax = 1.0\n",
    "\n",
    "# create datasets\n",
    "datasets = {}\n",
    "datasets['VR'] = VirtualReality()\n",
    "datasets['VR'].VR = True\n",
    "datasets['VR'].PC = False\n",
    "datasets['PC'] = VirtualReality()\n",
    "datasets['PC'].VR = False\n",
    "datasets['PC'].PC = True\n",
    "\n",
    "results = {}\n",
    "\n",
    "for subject in VirtualReality().subject_list:\n",
    "\n",
    "\tdata = {}\n",
    "\tdata['VR'] = {}\n",
    "\tdata['PC'] = {}\n",
    "\n",
    "\tembeddings = {}\n",
    "\tstats = {}\n",
    "\tstats['VR'] = {}\n",
    "\tstats['PC'] = {}\n",
    "\n",
    "\tfor condition in datasets.keys():\n",
    "\n",
    "\t\t# get the epochs and labels\n",
    "\t\tX, y, meta = paradigm.get_data(datasets[condition], subjects=[subject])\n",
    "\t\ty = LabelEncoder().fit_transform(y)\n",
    "\n",
    "\t\tdata[condition]['X'] = X\n",
    "\t\tdata[condition]['y'] = y\n",
    "\n",
    "\t\t# estimate xDawn covs\n",
    "\t\tncomps = 4\n",
    "\t\terp = XdawnCovariances(classes=[1], estimator='lwf', nfilter=ncomps, xdawn_estimator='lwf')\n",
    "\t\t#erp = ERPCovariances(classes=[1], estimator='lwf', svd=ncomps)\t\n",
    "\t\tsplit = train_test_split(X, y, train_size=0.50, random_state=42)\n",
    "\t\tXtrain, Xtest, ytrain, ytest = split\n",
    "\t\tcovs = erp.fit(Xtrain, ytrain).transform(Xtest)\n",
    "\n",
    "\t\tMtarget = mean_riemann(covs[ytest == 1])\n",
    "\t\tMnontarget = mean_riemann(covs[ytest == 0])\n",
    "\t\tstats[condition]['distance'] = distance_riemann(Mtarget, Mnontarget)\n",
    "\t\tstats[condition]['dispersion_target'] = np.sum([distance_riemann(covi, Mtarget)**2 for covi in covs[ytest == 1]]) / len(covs[ytest == 1])\n",
    "\t\tstats[condition]['dispersion_nontarget'] = np.sum([distance_riemann(covi, Mnontarget)**2 for covi in covs[ytest == 0]]) / len(covs[ytest == 0])\n",
    "\t\t\n",
    "\tprint('subject', subject)\n",
    "\tprint(stats)\n",
    "\n",
    "\tresults[subject] = stats\n",
    "\n",
    "\t# covs = np.concatenate([covs, Mtarget[None,:,:], Mnontarget[None,:,:]])\n",
    "\t# ytest = np.concatenate([ytest, [1], [0]])\n",
    "\t# data[condition]['ytest'] = ytest\n",
    "\n",
    "\t# # do the embedding\n",
    "\t# lapl = Embedding(metric='riemann', n_components=2)\n",
    "\t# embeddings[condition] = lapl.fit_transform(covs)\n",
    "\n",
    "dispersion_target_list = []\n",
    "dispersion_nontarget_list = []\n",
    "distance_list = []\n",
    "condition_list = []\n",
    "subject_list = []\n",
    "for subject in results.keys():\n",
    "\tresults_subj = results[subject]\n",
    "\tfor condition in ['VR', 'PC']:\n",
    "\t\tsubject_list.append(subject)\n",
    "\t\tcondition_list.append(condition)\n",
    "\t\tdispersion_target_list.append(results_subj[condition]['dispersion_target'])\n",
    "\t\tdispersion_nontarget_list.append(results_subj[condition]['dispersion_nontarget'])\n",
    "\t\tdistance_list.append(results_subj[condition]['distance'])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['subject'] = subject_list\n",
    "df['condition'] = condition_list\n",
    "df['dispersion_target']\t= dispersion_target_list\n",
    "df['dispersion_nontarget'] = dispersion_nontarget_list\n",
    "df['distance'] = distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
